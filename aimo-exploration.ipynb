{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73231,"databundleVersionId":8133715,"sourceType":"competition"},{"sourceId":7369493,"sourceType":"datasetVersion","datasetId":4281572},{"sourceId":5112,"sourceType":"modelInstanceVersion","modelInstanceId":3900},{"sourceId":5994,"sourceType":"modelInstanceVersion","modelInstanceId":4761},{"sourceId":11382,"sourceType":"modelInstanceVersion","modelInstanceId":8318},{"sourceId":11394,"sourceType":"modelInstanceVersion","modelInstanceId":8332}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":724.728315,"end_time":"2024-02-29T09:37:08.760349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-29T09:25:04.032034","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"21267b653022419eb6fc3f47aa4db8ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926e7ccdad6440be85c76931860b744c","placeholder":"​","style":"IPY_MODEL_feef8334edb24f6da22e8bb1d8d80c67","value":"Loading checkpoint shards: 100%"}},"2144e851698b4707ad1c7fc29fe21b03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3963993becfa487c9ff725f211915e67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a725e1b0cc4ad78a62beab5f663065","placeholder":"​","style":"IPY_MODEL_fdb32baaed7145d8a8024b615ef242ca","value":" 19/19 [10:48&lt;00:00, 33.24s/it]"}},"5882b6e860be4a0db012a64fc0704a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21267b653022419eb6fc3f47aa4db8ed","IPY_MODEL_d91eb83d016a4381828192a98f798f9b","IPY_MODEL_3963993becfa487c9ff725f211915e67"],"layout":"IPY_MODEL_6a892a5561f742bb9db9f13859c18e90"}},"6a892a5561f742bb9db9f13859c18e90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926e7ccdad6440be85c76931860b744c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91eb83d016a4381828192a98f798f9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2144e851698b4707ad1c7fc29fe21b03","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0693b32889c42b18b9a3844e045d048","value":19}},"e0693b32889c42b18b9a3844e045d048":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7a725e1b0cc4ad78a62beab5f663065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdb32baaed7145d8a8024b615ef242ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feef8334edb24f6da22e8bb1d8d80c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# credits: https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama\n# credits: https://www.kaggle.com/code/thedrcat/aimo-mixtral-baseline\n\n!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq","metadata":{"_uuid":"e0e2ea19-8108-4523-ab59-e77e349e14aa","_cell_guid":"c015e87b-c693-4e67-9708-54268996eb01","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-13T05:37:39.529876Z","iopub.execute_input":"2024-04-13T05:37:39.530770Z","iopub.status.idle":"2024-04-13T05:37:39.535027Z","shell.execute_reply.started":"2024-04-13T05:37:39.530732Z","shell.execute_reply":"2024-04-13T05:37:39.534038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports and Config","metadata":{}},{"cell_type":"code","source":"import gc\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n\nPRIVATE = True\ndevice = 'cuda'\nMODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Load","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\ntrain.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/test.csv')\ntest.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Load","metadata":{}},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)\n\n# To prevent GPU memory overflow in Mixtral8x7b\nconfig = AutoConfig.from_pretrained(MODEL_PATH)\nconfig.gradient_checkpointing = True\n\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_PATH,\n    device_map = \"auto\",\n    trust_remote_code = True,\n    quantization_config=quantization_config,\n    config=config\n)","metadata":{"_uuid":"7e2d0cc8-415c-453e-8bac-c6e385468db3","_cell_guid":"5332d1d8-f5bf-4c23-a9ef-5263e78b7062","collapsed":false,"papermill":{"duration":664.688061,"end_time":"2024-02-29T09:36:29.988515","exception":false,"start_time":"2024-02-29T09:25:25.300454","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-13T04:56:57.159344Z","iopub.execute_input":"2024-04-13T04:56:57.159669Z","iopub.status.idle":"2024-04-13T05:08:36.822380Z","shell.execute_reply.started":"2024-04-13T04:56:57.159640Z","shell.execute_reply":"2024-04-13T05:08:36.821580Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_prompt(problem):\n    \n    return f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\n### Instruction:\\n{problem}\\n\\n\n### Response: Let's think step by step. The final response should be a single number in the last line of your response.\n\"\"\"\n\ndef naive_parse(answer):\n    out = []\n    start = False\n    end = False\n    for l in reversed(list(answer)):\n        if l in '0123456789' and not end:\n            start = True\n            out.append(l)\n        else:\n            if start:\n                end = True\n        \n    out = reversed(out)\n    return int(''.join(out))","metadata":{"_uuid":"dc8acf11-4466-4e69-8bd1-6320303d9cd3","_cell_guid":"5179a0a2-c39b-4b7b-9d5f-ca125f500afe","collapsed":false,"papermill":{"duration":0.016537,"end_time":"2024-02-29T09:36:31.23871","exception":false,"start_time":"2024-02-29T09:36:31.222173","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-13T05:08:36.856020Z","iopub.execute_input":"2024-04-13T05:08:36.856318Z","iopub.status.idle":"2024-04-13T05:08:36.861887Z","shell.execute_reply.started":"2024-04-13T05:08:36.856292Z","shell.execute_reply":"2024-04-13T05:08:36.860802Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answers = []\n\nfor i in tqdm(range(len(test))):\n    try:\n        id_ = test['id'].loc[i]\n        problem = test['problem'].loc[i]\n        query_prompt = gen_prompt(problem)\n        \n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": query_prompt\n            }\n        ]\n        \n        ## Tokenizer -> convert into pytorch tensors and store on the GPU\n        inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n\n        # Run it through the model, no gradient descent, because this is inference. We are not training\n        with torch.no_grad():\n            encoded_output = model.generate(inputs, max_new_tokens=1500, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n\n        # Decode the output through the same tokenizer\n        decoded_output = tokenizer.decode(encoded_output[0], skip_special_tokens=True).replace(query_prompt, '').replace(\"[INST]\", \"\").replace(\"[/INST]\", \"\").strip()\n    \n        print(i)\n        print(decoded_output)\n        \n        answer = decoded_output.split('\\n')[-1]\n        answer = naive_parse(answer)\n        print(answer)\n        answer = int(answer) % 1000\n        print(answer)\n        answers.append(answer)\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n    except Exception as e:\n        print(e)\n        answers.append(0)","metadata":{"_uuid":"ae52cdf4-93d9-4e34-b93c-87c84ed8d4ee","_cell_guid":"0ab67780-9e5d-49e9-ac00-e99d5ff495a1","collapsed":false,"papermill":{"duration":34.259365,"end_time":"2024-02-29T09:37:05.548829","exception":false,"start_time":"2024-02-29T09:36:31.289464","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-13T05:25:03.899160Z","iopub.status.idle":"2024-04-13T05:25:03.899502Z","shell.execute_reply.started":"2024-04-13T05:25:03.899323Z","shell.execute_reply":"2024-04-13T05:25:03.899337Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['answer'] = answers","metadata":{"_uuid":"d83ce1e5-dbc9-4351-b533-a35575c01a82","_cell_guid":"1955407f-85ef-45df-97ab-92f68b9750d9","collapsed":false,"execution":{"iopub.status.busy":"2024-04-13T05:25:03.891538Z","iopub.status.idle":"2024-04-13T05:25:03.892051Z","shell.execute_reply.started":"2024-04-13T05:25:03.891768Z","shell.execute_reply":"2024-04-13T05:25:03.891788Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['id','answer']].to_csv(\"submission.csv\", header=True, index=False)","metadata":{"_uuid":"ba387159-7e7b-4566-a8f6-e3a4e9c1f7dd","_cell_guid":"fc80ae48-d69f-401f-816d-a00c5badebd4","collapsed":false,"papermill":{"duration":0.021128,"end_time":"2024-02-29T09:37:05.574782","exception":false,"start_time":"2024-02-29T09:37:05.553654","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-13T05:25:03.893538Z","iopub.status.idle":"2024-04-13T05:25:03.894026Z","shell.execute_reply.started":"2024-04-13T05:25:03.893768Z","shell.execute_reply":"2024-04-13T05:25:03.893787Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['id','answer']].head()","metadata":{"_uuid":"c8416479-4c94-4b31-a407-7560c5b8483a","_cell_guid":"5bde0471-6323-4dcc-bf69-dfbedecada1f","collapsed":false,"papermill":{"duration":0.014339,"end_time":"2024-02-29T09:37:05.594605","exception":false,"start_time":"2024-02-29T09:37:05.580266","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-13T05:25:03.895239Z","iopub.status.idle":"2024-04-13T05:25:03.895722Z","shell.execute_reply.started":"2024-04-13T05:25:03.895488Z","shell.execute_reply":"2024-04-13T05:25:03.895508Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}